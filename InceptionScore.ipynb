{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code derived from tensorflow/tensorflow/models/image/imagenet/classify_image.py\n",
    "# SSIM implementation can be found here: https://github.com/jterrace/pyssim\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import os.path\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'tmp/imagenet'\n",
    "DATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "softmax = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call this function with list of images. Each of elements should be a\n",
    "# numpy array with values ranging from 0 to 255.\n",
    "def get_inception_score(images, splits=10):\n",
    "    assert type(images) == list\n",
    "    assert type(images[0]) == np.ndarray\n",
    "    assert len(images[0].shape) == 3\n",
    "    assert np.max(images[0]) > 10\n",
    "    assert np.min(images[0]) >= 0.0\n",
    "    inps = []\n",
    "    for img in images:\n",
    "        img = img.astype(np.float32)\n",
    "        inps.append(np.expand_dims(img, 0))\n",
    "    bs = 100\n",
    "    with tf.Session() as sess:\n",
    "        preds = []\n",
    "        n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n",
    "        for i in range(n_batches):\n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            inp = inps[i * bs:min((i + 1) * bs, len(inps))]\n",
    "            inp = np.concatenate(inp, 0)\n",
    "            pred = sess.run(softmax, {'ExpandDims:0': inp})\n",
    "            preds.append(pred)\n",
    "        preds = np.concatenate(preds, 0)\n",
    "        scores = []\n",
    "        for i in range(splits):\n",
    "            part = preds[i * preds.shape[0] // splits:(i + 1)\n",
    "                         * preds.shape[0] // splits, :]\n",
    "            kl = part * (np.log(part)\n",
    "                         - np.log(np.expand_dims(np.mean(part, 0), 0)))\n",
    "            kl = np.mean(np.sum(kl, 1))\n",
    "            scores.append(np.exp(kl))\n",
    "        return (np.mean(scores), np.std(scores))\n",
    "\n",
    "\n",
    "# This function is called automatically.\n",
    "\n",
    "def _init_inception():\n",
    "    global softmax\n",
    "    if not os.path.exists(MODEL_DIR):\n",
    "        os.makedirs(MODEL_DIR)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(MODEL_DIR, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename,\n",
    "                             float(count * block_size)\n",
    "                             / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        (filepath, _) = urllib.request.urlretrieve(DATA_URL, filepath,\n",
    "                _progress)\n",
    "        print ()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print ('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n",
    "    with tf.gfile.FastGFile(os.path.join(MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    # Works with an arbitrary minibatch size.\n",
    "    with tf.Session() as sess:\n",
    "        pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "        ops = pool3.graph.get_operations()\n",
    "        for (op_idx, op) in enumerate(ops):\n",
    "            for o in op.outputs:\n",
    "                shape = o.get_shape()\n",
    "                shape = [s.value for s in shape]\n",
    "                new_shape = []\n",
    "                for (j, s) in enumerate(shape):\n",
    "                    if s == 1 and j == 0:\n",
    "                        new_shape.append(None)\n",
    "                    else:\n",
    "                        new_shape.append(s)\n",
    "                o._shape = tf.TensorShape(new_shape)\n",
    "        w = sess.graph.get_operation_by_name('softmax/logits/MatMul').inputs[1]\n",
    "        logits = tf.matmul(tf.squeeze(pool3), w)\n",
    "        softmax = tf.nn.softmax(logits)\n",
    "\n",
    "\n",
    "if softmax is None:\n",
    "    _init_inception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(100):\n",
    "    images.append(np.array(Image.open(\"S:\\\\Projects\\\\MVC\\\\64x64_clean\\\\\" + str(i) + \".jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS = get_inception_score(images)\n",
    "print(IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
